{
  "Objective": {
    "required_elements": {
      "Dashboard": "Nothing.nothing"
    },
    "page_settings": {
      "title": "Objective",
      "description": "Aims of this dashboard and project",
      "icon": "Icon",
      "color": "Color",
      "filter_key": "Objective",
      "target_label": "Objective_page",
      "data": "Data"
    },
    "tab_contents": {
      "tab1": {
        "Header": {
          "type": "sub header",
          "content": "Objectives and Requirements"
        },
        "Upper": {
          "type": "markdown",
          "content": "#### Objective\n* The objective of this analysis is to identify patterns that can help distinguish between real and fake news.\n* The analysis includes the following steps:\n  * Data Preparation\n  * Exploratory Data Analysis\n  * Feature Engineering\n  * Model Building\n  * Model Evaluation\n  * Model Deployment\n---"
        },
        "Upper_left": {
          "type": "sub header",
          "content": "Suggested Data Sources"
        },
        "Lower_left": {
          "type": "markdown",
          "content": "The following datasets were initially discovered through a Google search: \n\n- **[Debunk Disinformation Analysis Center](https://www.debunk.org/?gad_source=1&gclid=CjwKCAjwvr--BhB5EiwAd5YbXs1x7Q9xNloMlUT7hUFllO27GXSkWOvoQ5uIPB62zLv3Akwvy3XdiBoCvZEQAvD_BwE)**\n- **[webz.io Fake News Data Repository](https://github.com/Webhose/fake-news-dataset)**\n- **[UNESCO: Data Sources](https://core.unesco.org/en/home)**\n\nOr one of the Kaggle datasets such as: \n\n- **[BBC Articles Dataset](https://www.kaggle.com/datasets/jacopoferretti/bbc-articles-dataset)**\n- **[Fake News Classification Dataset](https://www.kaggle.com/datasets/aadyasingh55/fake-news-classification)**\n- **[Fake or Real News Dataset](https://www.kaggle.com/datasets/nitishjolly/news-detection-fake-or-real-dataset)**\n- **[AI vs Human Text Dataset](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text)**\n- **[Fake News Detection (2015-2017)](https://www.kaggle.com/datasets/bhavikjikadara/fake-news-detection)**\n- **[Fake News Dataset](https://www.kaggle.com/datasets/algord/fake-news)**\n- **[PolitiFact Fact-Check Dataset](https://www.kaggle.com/datasets/rmisra/politifact-fact-check-dataset)**\n- **[Misinformation & Fake News Text Dataset (79K)](https://www.kaggle.com/datasets/stevenpeutz/misinformation-fake-news-text-dataset-79k)**\n- **[Non-English Fake News Dataset](https://www.kaggle.com/datasets/cryptexcode/banfakenews)**\n- **[Fake/Real News Dataset (2013-2020)](https://www.kaggle.com/datasets/techykajal/fakereal-news)**\n- **[Fake News Dataset Around the Syrian War (2014-2018)](https://www.kaggle.com/datasets/mohamadalhasan/a-fake-news-dataset-around-the-syrian-war)**"
        },
        "Upper_right": {
          "type": "sub header",
          "content": "Data Source(s) Used"
        },
        "Lower_right": {
          "type": "markdown",
          "content": "The first dataset used was:\n\n[Fake News Detection (2015-2017)](https://www.kaggle.com/datasets/bhavikjikadara/fake-news-detection)\n\n This was later enhanced with:\n\n[Misinformation & Fake News Text Dataset (79K)](https://www.kaggle.com/datasets/stevenpeutz/misinformation-fake-news-text-dataset-79k)"
        }
      },
      "tab2": {
        "Header": { "type": "sub header", "content": "Requirements" },
        "Upper": {
          "type": "text",
          "content": "To help with the design of the dashboard, two personas were created on ChatGPT to help with requirements gathering, one was Joe Bloggs a member of the public and the other was Julia Dempsey an IT and Data Reporter who is commissioning the dashboard and liaising with IT.  It then responded back based on what was achievable in the time limit and with the available data."
        },
        "Upper_right": {
          "type": "sub header",
          "content": "Julia Depseys communications with IT"
        },
        "Lower_right": {
          "type": "markdown",
          "content": "Through discussion The IT team have decided to build the initial model based of Real/Fake news datasets available on Kaggle and then potentially link it one or several of the API's to provide recent data for display on the dashboard whilst providing users the opportunity to provide a URL or text sample to the dashboard for scoring - You are now Julia Dempsy and need to highlight the most relevant requirements from Joes feedback, enhance them with your knowledge of the sector, and feedback from IT and make a requirements request to your IT team who have 4 days available to deliver the dashboard using python.. the learning model has not been developed yet and potential existing sources for some of Joe's requirements would help them to meet more requirements with out needing to go to first principles on all of them.\n\n**Subject:** Requirements for Fake News Detection Dashboard (4-Day Build)\n\n**Team,**\n\nBased on feedback from potential users and industry knowledge, we need a public-facing dashboard to help users verify the credibility of news stories. You have **4 days** to build a functional prototype in **Python**. The learning model will be initially built using **Real/Fake news datasets from Kaggle**, with the potential to integrate **fact-checking APIs** for real-time data. Users will also have the ability to **input a news article URL or text snippet** for analysis. Below are the **updated core requirements**:\n\n---\n\n#### **1. Dashboard Overview & UI/UX**\n- Simple, intuitive UI with a **trust score indicator** (e.g., traffic light system or percentage-based confidence level).\n- Users should be able to enter a **news article URL or text snippet** for evaluation.\n- Mobile-friendly and accessible design.\n\n#### **2. Fact-Checking & Source Verification**\n- **Integrate with existing fact-checking APIs** (e.g., Snopes, PolitiFact, FactCheck.org) to retrieve existing evaluations.\n- Display **source credibility history** (e.g., Media Bias Fact Check, NewsGuard API if available).\n- Link model-generated predictions with real-time API results where possible.\n\n#### **3. Machine Learning Model (Initial Phase)**\n- Train a **binary classification model** on Kaggle's **Real/Fake news datasets**.\n- Use **TF-IDF, word embeddings, or transformer-based NLP models** for classification.\n- Implement model inference for **user-submitted URLs or text samples**.\n\n#### **4. Bias & Manipulation Analysis**\n- Implement **basic NLP sentiment analysis** (positive, neutral, negative) using libraries like **NLTK or TextBlob**.\n- Detect **clickbait-style headlines** (e.g., based on word patterns from datasets like Clickbait Challenge).\n\n#### **5. Fake News Trends & Alerts**\n- Show a **real-time list of trending fake news stories** using sources like **Google Fact Check Tools** or Twitter API.\n- Display a **heatmap of misinformation spread** (if location-based misinformation data is available).\n\n#### **6. Image & Video Verification (Stretch Goal)**\n- Integrate **Google Reverse Image Search API** or tools like TinEye.\n- Investigate **deepfake detection** models (e.g., Deepware Scanner API) for future implementation.\n\n#### **7. Community & Expert Input**\n- Allow users to **flag articles** as suspicious (store in a database for future analysis).\n- Display community votes (e.g., 'Trusted' vs. 'Unverified') with moderation controls.\n\n#### **8. Educational Tools**\n- Provide a short, interactive **'How to Spot Fake News' guide**.\n- Weekly updates on **major misinformation trends**.\n\n---\n\n#### **Tech Stack Recommendation**\n- **Backend:** Flask or FastAPI for API handling.\n- **Frontend:** Streamlit (fastest for a 4-day build).\n- **Data Processing:** Pandas, NLTK, TextBlob for NLP.\n- **Machine Learning:** Scikit-learn, TensorFlow, or Hugging Face transformers.\n- **APIs:** Snopes, PolitiFact, Google Fact Check Tools, Media Bias Fact Check (if accessible).\n- **Storage:** SQLite or Firebase for tracking flagged articles.\n\n**Next Steps:**\n1. Train an initial model using **Kaggle datasets**.\n2. Confirm availability of fact-checking APIs.\n3. Assign core tasks based on expertise.\n4. Deliver a working prototype by **Day 4**.\n\nLet me know if you need further clarification.\n\n**Best,**\nJulia Dempsey "
        },
        "Upper_left": {
          "type": "sub header",
          "content": "Joe Bloggs Requirements"
        },
        "Lower_left": {
          "type": "markdown",
          "content": "You are Joe Bloggs a 25 year old office worker who is interested in being able to confirm if a news story is Real or Fake - you have been approached by a Julia Dempsy a reporter on IT and Data issues to ask your opinions on what functionality you would like to see on a public facing dashboard that has been trained to provide an estimate on whether a news story is Real or Fake and also to provide useful metrics on the level, scale and nature of previous fake news items\n\nJoe Bloggs' Response to Julia Dempsey (IT and Data Reporter):\n\n\"Hi Julia, thanks for reaching out! As someone who spends a lot of time online, I’d love a dashboard that makes it easy for everyday people like me to quickly check if a news story is real or fake. Here’s what I’d want to see and how it could help me make better judgments:\"\n\n1. **Quick Trust Score & Rating System**\n   - A simple traffic light system (Green = Likely Real, Yellow = Unverified, Red = Likely Fake).\n   - A percentage-based trust score based on AI analysis and fact-checking sources.\n   - A “Confidence Level” indicator showing how certain the system is about its assessment.\n2. **Fact-Checking & Source Analysis**\n   - Links to major fact-checking websites (e.g., Snopes, PolitiFact, BBC Reality Check).\n   - A summary of key fact-checked points in the article.\n   - Information on the news source, including any history of publishing false stories.\n3. **Bias & Manipulation Detection**\n   - A breakdown of potential political or ideological bias in the article.\n   - Sentiment analysis (Is it overly emotional or neutral?).\n   - AI detection of misleading language, clickbait, or exaggeration.\n4. **Fake News Trends & Warnings**\n   - A list of trending fake news stories circulating right now.\n   - Alerts for viral misinformation and debunked claims.\n   - An interactive map showing where fake news is spreading most.\n5. **Image & Video Verification**\n   - Reverse image search integration to see if a photo has been used out of context.\n   - AI detection of manipulated images or deepfakes.\n   - A credibility check for videos, detecting edited or misleading clips.\n6. **Community & Expert Reviews**\n   - A “User Reports” section showing how many people flagged a story as fake.\n   - A credibility ranking system where journalists, experts, and the public can contribute.\n   - A way to submit suspicious articles for fact-checking.\n7. **Educational Tools**\n   - A quick guide on “How to Spot Fake News.”\n   - Interactive quizzes to help users improve their fake news detection skills.\n   - A weekly “Fake News Roundup” showing the biggest misinformation stories exposed.\n\n\"I think a dashboard like this would be incredibly useful, especially for people who don’t have time to do deep research on every news story. The key thing is making it simple, fast, and accessible for anyone to use.\"\n\n\"Would love to hear your thoughts on this—does this align with what you’re looking for?\""
        }
      },
      "tab3": {
        "Header": {
          "type": "sub header",
          "content": "Outcome and Summary"
        },
        "Upper": {
          "type": "markdown",
          "content": "### Dashboard Aims and Requirements\n\nFollowing analysis of the available data, the following aims and requirements were agreed for the initial release of the dashboard:\n\n1. **Objective**:\n   - To produce a dashboard that presents a Machine Learning (ML) model capable of analyzing a news article and providing a classification of **Real** or **Dubious**.\n\n2. **Features**:\n   - The dashboard will include visualizations to help users better understand the differences between **Real** and **Dubious** news.\n\n3. **Technology**:\n   - The dashboard will be built using **Python** and implemented as a **Streamlit application**.\n\n4. **Analysis Tools**:\n   - TextBlob sentiment analysis algorithms will be used for data analysis.\n\n5. **Dataset**:\n   - The **Fake News Detection (2015-2017)** dataset from Kaggle will be utilized.\n\n6. **Timeline**:\n   - The dashboard will be developed as a **4-day prototype**.\n\n7. **Future Goals**:\n   - It is anticipated that the next generation of the dashboard will address more user requests and potentially integrate **fact-checking APIs**."
        },
        "Visualizations": {
          "type": "markdown",
          "content": "### Analysis Summary\n\nThe analysis of the words used by **Real** and **Dubious** news stories revealed the following insights:\n\n1. **Sentiment Analysis**:\n   - The use of **TextBlob sentiment analysis algorithms** showed differences in the sentiment of titles and articles.\n   - **Polarity and Subjectivity** analysis indicated:\n     - Titles were generally more **positive** and **less subjective** than articles, regardless of their truthfulness.\n     - Titles had a **higher median score** for both polarity and subjectivity.\n     - Articles exhibited a **wider range of scores** and more outliers.\n\n2. **Data Bias**:\n   - The data was **biased**, with **Real** and **Dubious** news articles being classified differently.\n   - Only **Real articles** had identified sources.\n   - The **category** field was also biased, with **Real news stories** being less extreme in polarity and less subjective than **Dubious news stories**.\n\n3. **Character Count Analysis**:\n   - **Real news articles** had a **lower character length** in both titles and articles compared to **Dubious news articles**.\n   - The further the character count deviated from this, the greater the chance the article was **not real**.\n\n4. **Content Indicators**:\n   - Articles that mention **videos or pictures**, especially in the title, were more likely to be **Dubious news**.\n   - Articles referencing **key social media outlets** were more likely to be **Real**.\n\n---\n\n### Conclusion\n\nA dashboard has been successfully built that can provide a **Real or Dubious classification** based on the **sentiment of the title and article** for any submitted article."
        }
      }
    }
  },
  "Data Exploration": {
    "required_elements": {
      "Dashboard": "sl_visualisations.polarity_refactor.plot_article_vs_title_polarity",
      "vis1": "sl_visualisations.article_count_refactor.plot_article_count_by_subject",
      "vis2": "sl_visualisations.article_count_refactor.plot_article_count_by_source",
      "vis3": "sl_visualisations.other_visuals_refactor.plot_article_vs_title_characters",
      "vis4": "sl_visualisations.article_count_refactor.plot_article_count_by_media",
      "vis5": "sl_visualisations.other_visuals_refactor.plot_hex_charcounts"
    },
    "page_settings": {
      "title": "Data Exploration",
      "description": "Page to show output of the EDA process.",
      "icon": "Icon",
      "color": "green",
      "filter_key": "Filter Key",
      "target_label": "EDA_output",
      "data": "data_clean"
    },
    "tab_contents": {
      "tab1": {
        "Header": { "type": "header", "content": "Topline Observations" },
        "Upper": {
          "type": "text",
          "content": "During the EDA it was noticed that, several of the data columns available were biased. That is how they had been set meant that it was possible to identify Real or Dubious news solely by their content. The two main offenders of this were the Source Name - only Real articles had identified sources, and the category. Although the category appeared neutral at first glance, analysis showed that in fact Real articles received different categorization than Dubious news stories"
        },
        "Lower_left": {
          "type": "text",
          "content": "Now it is probably not surprising that Articles which quote their source, are almost always Real, especially if the source is a recognised agency.  The data alas has limited variation in the sources identified and as such potentially this should be an item for future investigation."
        },
        "Upper_left": {
          "type": "visualization",
          "content": "sl_visualisations.article_count_refactor.plot_article_count_by_source"
        },
        "Lower_right": {
          "type": "text",
          "content": "As can be seen, there is a definite bias in the data.  With Dubious and Real news articles being classified differently."
        },
        "Upper_right": {
          "type": "visualization",
          "content": "sl_visualisations.article_count_refactor.plot_article_count_by_subject"
        }
      },
      "tab2": {
        "Header": {
          "type": "sub header",
          "content": "Character Counts and Media Types"
        },
        "Upper": {
          "type": "text",
          "content": "The first analysis undertaken after a look at the neutrality of the data, was to see if the number of characters in the Title or Article could be an indicator of how Real an article was.  This did provide some interesting results."
        },
        "Upper_left": {
          "type": "visualization",
          "content": "sl_visualisations.other_visuals_refactor.plot_article_vs_title_characters"
        },
        "Lower_left": {
          "type": "text",
          "content": "It is evident that Real news articles have a char length between X and Y, and the further the count is from this the greater the chance that the article is not real."
        },
        "Upper_right": {
          "type": "visualization",
          "content": "sl_visualisations.article_count_refactor.plot_article_count_by_media"
        },
        "Lower_right": {
          "type": "text",
          "content": "Articles that mention videos or pictures especially in the title, are more likely to be Dubious news.  The data was from 2014-2017, and as such also articles which referenced the key Social Media outlets is shown to be more likely Real.  It would be interesting to see how this has changed since several of these organisations have decreased on site fact checking."
        }
      },
      "tab3": {
        "Header": {
          "type": "header",
          "content": "Number of Articles in the DataSet over time"
        },
        "Upper": {
          "type": "text",
          "content": "A better presentation of the comparison of character counts in title and article by Real and Dubious news articles."
        },
        "Visualizations": {
          "type": "visualization",
          "content": "sl_visualisations.other_visuals_refactor.plot_hex_charcounts"
        }
      }
    }
  },
  "Data Preprocessing": {
    "required_elements": {
      "T1C1V1": "sl_visualisations.polarity_refactor.plot_article_vs_title_polarity",
      "T1C2V1": "sl_visualisations.subjectivity_refactor.plot_article_vs_title_subjectivity",
      "T2C1V1": "sl_visualisations.subjectivity_refactor.plot_title_subjectivity_vs_polarity",
      "T2C1V2": "sl_visualisations.subjectivity_refactor.plot_article_subjectivity_vs_polarity",
      "T2C2V1": "sl_visualisations.polarity_refactor.plot_polarity_contrad_variations",
      "T2C2V2": "sl_visualisations.subjectivity_refactor.plot_subjectivity_contrad_variations",
      "T3C1V1": "sl_visualisations.boxplot_visuals.plot_polarity_subjectivity_boxplots"
    },
    "page_settings": {
      "title": "Data PreProcessing",
      "description": "Data manipulations post ETL and pre modelling.",
      "icon": "Icon",
      "color": "Color",
      "filter_key": "DataPreProcessing",
      "target_label": "DataPreProcessing",
      "data": "Data_Clean"
    },
    "tab_contents": {
      "tab1": {
        "Header": {
          "type": "sub header",
          "content": "Polarity and Subjectivity"
        },
        "Upper": {
          "type": "text",
          "content": "After extracting the data, dealing with missing data and duplicates, several new measures were created to support understanding.  Two of these were Polarity and Subjectivity - these are two measures calculated using TextBlob's data analytics models.  Polarity measures how Postive or Negative a section of text is ranging from -1 very negative to 1 very positive.  The polarity score for the title and text of each article were calculated and then compared.  Subjectivity is a measure of how objective (evidence based) or subjective (emotion based) a piece of text is.  It is represented as a score between 0 very objective to 1 very subjective, again the scores for both the title and text were calculated and analysed.  Then the difference/contradictiveness of sentiments between the title and text were compared as well as the degree of variance between their relative polarities and subjectivities."
        },
        "Upper_left": {
          "type": "text",
          "content": "The visualisation below compared the polarity of the Title of an article to that of the main text and distinguishes articles that are Real or Dubious."
        },
        "Lower_left": {
          "type": "visualization",
          "content": "sl_visualisations.polarity_refactor.plot_article_vs_title_polarity"
        },
        "Upper_right": {
          "type": "text",
          "content": "sl_The visualisation below does the same for Subjectivity."
        },
        "Lower_right": {
          "type": "visualization",
          "content": "sl_visualisations.subjectivity_refactor.plot_article_vs_title_subjectivity"
        }
      },
      "tab2": {
        "Header": {
          "type": "sub header",
          "content": "Contradictions and Variations"
        },
        "Upper": {
          "type": "text",
          "content": "For reference on the left are the comparisons of the Titles Polarity vs Titles Subjectivity and the same for articles.  Then on the right we have a look at the contradictions in subjectivity vs polarity and the variances."
        },
        "Upper_left": {
          "type": "visualization",
          "content": "sl_visualisations.subjectivity_refactor.plot_title_subjectivity_vs_polarity"
        },
        "Lower_left": {
          "type": "visualization",
          "content": "sl_visualisations.subjectivity_refactor.plot_article_subjectivity_vs_polarity"
        },
        "Lower_right": {
          "type": "visualization",
          "content": "sl_visualisations.polarity_refactor.plot_polarity_contrad_variations"
        },
        "Upper_right": {
          "type": "visualization",
          "content": "sl_visualisations.subjectivity_refactor.plot_subjectivity_contrad_variations"
        }
      },
      "tab3": {
        "Header": {
          "type": "sub header",
          "content": "Box Plots to look at distribution of Polarity and Subjectivity"
        },
        "Upper": {
          "type": "text",
          "content": "These box plots show the distribution of Polarity and Subjectivity scores for both the Title and the Article.  The Title is shown in blue and the Article in orange.  The box plots show the median, the interquartile range and the outliers.  The Title is generally more positive and less subjective than the Article.  The Article has a wider range of scores and more outliers.  The Title has a higher median score than the Article for both Polarity and Subjectivity."
        },
        "Visualizations": {
          "type": "visualization",
          "content": "sl_visualisations.boxplot_visuals.plot_polarity_subjectivity_boxplots"
        }
      }
    }
  },
  "Word Data Analysis": {
    "required_elements": {},
    "page_settings": {
      "title": "Word and Phrase Analysis",
      "description": "Word and Phrase Analysis.",
      "icon": "Icon",
      "color": "Color",
      "filter_key": "word_data_analysis",
      "target_label": "word_data_analysis",
      "data": "Data_Clean"
    },
    "tab_contents": {
      "tab1": {
        "Header": {
          "type": "sub header",
          "content": "Wordclouds for 2017"
        },
        "Upper": {
          "type": "markdown",
          "content": "The word clouds below are for 2017. It is interesting to see that there are little differences in the words used in Real and Dubious articles.  The word clouds below show the most common words in Real and Dubious articles.  The top left is the words in all articles analysed, the top right is the words in Real articles, the bottom left is the words in Dubious articles and the bottom right is the words that are common in both Real and dubious articles."
        },
        "Upper_left": {
          "type": "image",
          "content": "wordclouds//wordcloud_all_2017.png"
        },
        "Lower_left": {
          "type": "image",
          "content": "wordclouds//wordcloud_dubious_2017.png"
        },
        "Upper_right": {
          "type": "image",
          "content": "wordclouds//wordcloud_real_2017.png"
        },
        "Lower_right": {
          "type": "image",
          "content": "wordclouds//wordcloud_common_2017.png"
        }
      },
      "tab2": {
        "Header": {
          "type": "sub header",
          "content": "Word clouds for 2016"
        },
        "Upper": {
          "type": "markdown",
          "content": "### Word Clouds Analysis 2016 \n\nIt is interesting to see that there are little differences in the words again used in Real and Dubious articles.  The word clouds below show the most common words in Real and Dubious articles.  The top left is the words in all articles analysed, the top right is the words in Real articles, the bottom left is the words in Dubious articles and the bottom right is the words that are common in both Real and dubious articles. There are some obvious exceptions such as the word the mention of Clinton, people, image and hillary which are mentioned more in Dubious articles.  The word cloud for all articles is also interesting as it shows the most common words in all articles analysed."
        },
        "Upper_left": {
          "type": "image",
          "content": "wordclouds//wordcloud_all_2016.png"
        },
        "Lower_left": {
          "type": "image",
          "content": "wordclouds//wordcloud_dubious_2016.png"
        },
        "Lower_right": {
          "type": "image",
          "content": "wordclouds//wordcloud_real_2016.png"
        },
        "Upper_right": {
          "type": "image",
          "content": "wordclouds//wordcloud_common_2016.png"
        }
      },
      "tab3": {
        "Header": {
          "type": "header",
          "content": "Unique words and Phrases in Real and Dubious articles"
        },
        "Upper": {
          "type": "markdown",
          "content": "The visualisation below looks at unique phrases in articles the first image is the unique words in 2016 real articles, the second is the unique words in 2016 dubious articles, the third is the unique words in 2017 real articles and the last is the unique words in 2017 dubious articles.  The images are word clouds and show the most common phrases in each of the articles."
        },
        "Visualizations": {
          "type": "markdown",
          "content": "[[imageblock]]\nwordclouds/wordcloud_real_unique_2016.png\nwordclouds/wordcloud_dubious_unique_2016.png\nwordclouds/wordcloud_real_unique_2017.png\nwordclouds/wordcloud_dubious_unique_2017.png"
        }
      }
    },
    "Machine Learning": {
      "required_elements": {
        "ROD_Dashboard": "sl_visualisations.map_visualisation.display_maps"
      },
      "page_settings": {
        "title": "Machine Learning Modelling",
        "description": "Information on Machine Learning Modelling",
        "icon": "Icon",
        "color": "Color",
        "filter_key": "Filter Key",
        "target_label": "Target Label",
        "data": "Data"
      },
      "tab_contents": {
        "tab1": {
          "Header": {
            "type": "sub header",
            "content": "Model to classify if an article is Real or Dubious"
          },
          "Upper": {
            "type": "markdown",
            "content": "Several models were made and assessed including Linear Regression and Random Forest, before settling on the deployed one."
          },
          "Upper_left": {
            "type": "markdown",
            "content": "### Model Performance\n\nThe original models only achieved **50-60% accuracy**, so alternatives were explored. The final model achieves an impressive **93-94% accuracy** on analysis.\n\n#### Key Observations:\n- There is still a degree of **False Positives** and **False Negatives**.\n- **False Positives**: These represent **badly written Real news**.\n- **False Negatives**: These represent **well-constructed Dubious news**.\n\nWhile the model performs well, further refinements are needed to reduce these errors and improve reliability."
          },
          "Lower_left": { "type": "header", "content": "content" },
          "Upper_right": { "type": "header", "content": "content" },
          "Lower_right": { "type": "header", "content": "content" }
        },
        "tab2": {
          "Header": { "type": "header", "content": "content" },
          "Upper": { "type": "header", "content": "content" },
          "Upper_left": { "type": "header", "content": "content" },
          "Lower_left": { "type": "header", "content": "content" }
        },
        "tab3": {
          "Header": {
            "type": "header",
            "content": ""
          },
          "Upper": {
            "type": "text",
            "content": ""
          },
          "Visualizations": {
            "type": "visualization",
            "content": ""
          }
        }
      }
    }
  }
}
